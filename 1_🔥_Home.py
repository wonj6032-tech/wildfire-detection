# 1_ğŸ”¥_Home.py â€” Wildfire Detection (Image + Video, Live HUD, Streaming)
# Streamlit Cloud (CPU) ìµœì í™”: ìŠ¤íŠ¸ë¦¬ë° ì¶”ë¡  + í”„ë ˆì„ ë“œë¡­ + í•´ìƒë„ ì¶•ì†Œ + ìŠ¤ë ˆë“œ íŠœë‹
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

import io
import time
import tempfile
from glob import glob
from datetime import datetime

import cv2
import requests
import streamlit as st
import numpy as np
from numpy import random
from PIL import Image
from ultralytics import YOLO

# --- CPU thread tuning (Streamlit Cloud) ---
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
try:
    import torch
    torch.set_num_threads(1)
    cv2.setNumThreads(0)
except Exception:
    pass


# ========================= ìœ í‹¸ =========================

def _rgb(img_bgr):
    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

def _resize_keep_aspect(frame, target_w=None, max_w=None):
    h, w = frame.shape[:2]
    if target_w is not None and target_w > 0 and w != target_w:
        new_w = int(target_w)
        new_h = int(h * (new_w / w))
        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
    if max_w is not None and w > max_w:
        new_w = int(max_w)
        new_h = int(h * (new_w / w))
        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return frame

def _safe_names(model, res0=None):
    if res0 is not None and hasattr(res0, "names") and res0.names:
        return res0.names
    if hasattr(model, "names") and model.names:
        return model.names
    if hasattr(model, "model") and hasattr(model.model, "names"):
        return model.model.names
    return {0: "object"}

def _looks_like_lfs_pointer(path: str) -> bool:
    try:
        with open(path, "rb") as f:
            head = f.read(256)
        return b"git-lfs" in head or b"oid sha256" in head or b"version https://git-lfs.github.com/spec" in head
    except Exception:
        return False

def _resolve_video_source(src: str) -> str:
    """
    ì›ê²© URLì´ë©´ ì„ì‹œíŒŒì¼ë¡œ ë°›ì•„ì„œ OpenCV/Ultralyticsê°€ ì•ˆì •ì ìœ¼ë¡œ ì—´ë„ë¡ ë³€í™˜.
    """
    if isinstance(src, str) and src.startswith(("http://", "https://")):
        suffix = os.path.splitext(src)[1] or ".mp4"
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        with requests.get(src, stream=True, timeout=60) as r:
            r.raise_for_status()
            size = 0
            for chunk in r.iter_content(1 << 20):
                if chunk:
                    tmp.write(chunk)
                    size += len(chunk)
        tmp.flush()
        st.caption(f"Downloaded video â†’ {os.path.basename(tmp.name)} ({round(size/1_048_576,2)} MB)")
        return tmp.name
    return src


# ========================= ëª¨ë¸ ë¡œë” =========================

@st.cache_resource
def load_model(model_path: str | None):
    """
    1) ì§€ì • ê²½ë¡œ .pt ë¡œë“œ
    2) ì‹¤íŒ¨ ì‹œ ì €ì¥ì†Œì˜ general-models/yolov8n.pt í´ë°±
    3) ìµœì¢… í´ë°±: íŒ¨í‚¤ì§€ yolov8n.pt
    """
    if model_path and os.path.exists(model_path) and os.path.getsize(model_path) > 100_000 and not _looks_like_lfs_pointer(model_path):
        try:
            return YOLO(model_path)
        except Exception as e:
            st.warning(f"ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨({e}). í´ë°± ì‹œë„â€¦")

    fallback_local = os.path.join("general-models", "yolov8n.pt")
    if os.path.exists(fallback_local) and not _looks_like_lfs_pointer(fallback_local):
        try:
            return YOLO(fallback_local)
        except Exception as e:
            st.warning(f"ë¡œì»¬ í´ë°± ë¡œë“œ ì‹¤íŒ¨({e}). ìµœì¢… í´ë°± ì‹œë„â€¦")

    return YOLO("yolov8n.pt")


# ========================= ì¶”ë¡  (ì´ë¯¸ì§€) =========================

def predict_image(model, image_pil: Image.Image, conf_threshold: float, iou_threshold: float):
    img_bgr = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
    res = model.predict(img_bgr, conf=conf_threshold, iou=iou_threshold, device='cpu', verbose=False)
    res0 = res[0] if res else None
    names = _safe_names(model, res0)
    classes = res0.boxes.cls if (res0 is not None and res0.boxes is not None) else []
    class_counts = {}
    if classes is not None:
        for c in classes:
            c = int(c)
            cname = names[c] if isinstance(names, (list, tuple)) else names.get(c, str(c))
            class_counts[cname] = class_counts.get(cname, 0) + 1

    if class_counts:
        parts = [f"{v} {k}{'s' if v > 1 else ''}" for k, v in sorted(class_counts.items(), key=lambda x: x[1], reverse=True)]
        text = "Predicted " + ", ".join(parts)
    else:
        text = "No objects detected"

    latency_ms = sum(res0.speed.values()) if (res0 is not None and hasattr(res0, "speed")) else 0.0
    text += f" in {round(latency_ms / 1000, 2)} seconds."
    vis = res0.plot() if res0 is not None else img_bgr
    return _rgb(vis), text


# ========================= ì¶”ë¡  (ë¹„ë””ì˜¤ â€” ìŠ¤íŠ¸ë¦¬ë° + ë¼ì´ë¸Œ HUD) =========================

def predict_video(model,
                  source,
                  conf_threshold: float,
                  iou_threshold: float,
                  frame_skip: int = 2,
                  resize_w: int | None = 960,
                  max_frames: int = 1800,
                  stop_key: str = "stop_video",
                  hud: bool = True,
                  imgsz: int = 480,        # YOLO ì…ë ¥ ì‚¬ì´ì¦ˆ(ì‘ì„ìˆ˜ë¡ ë¹ ë¦„) 384~512 ê¶Œì¥
                  target_fps: int = 12,    # í™”ë©´ ê°±ì‹  ëª©í‘œ FPS (ìŠ¤ë¡œí‹€) 10~15 ê¶Œì¥
                  preview: bool = False):
    """
    Ultralytics ìŠ¤íŠ¸ë¦¬ë° ì¶”ë¡  + FPS ìŠ¤ë¡œí‹€ + í”„ë ˆì„ ë“œë¡­.
    """
    import collections
    from time import perf_counter, sleep

    def _put_text(img, text, y, color=(0, 255, 0)):
        cv2.putText(img, text, (12, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)

    path = _resolve_video_source(source)
    if preview:
        st.video(path)  # í•„ìš” ì‹œë§Œ ë””ì½”ë” ì²´í¬ìš©

    # Stop ë²„íŠ¼
    if stop_key not in st.session_state:
        st.session_state[stop_key] = False
    cols = st.columns([1, 4, 1])
    with cols[0]:
        if st.button("â¹ Stop"):
            st.session_state[stop_key] = True

    # YOLO ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° (ë‚´ë¶€ì—ì„œ í”„ë ˆì„ ì½ê¸°)
    gen = model.predict(
        source=path,
        stream=True,
        conf=conf_threshold,
        iou=iou_threshold,
        imgsz=imgsz,            # ì…ë ¥ ë‹¤ìš´ìŠ¤ì¼€ì¼ë§ (ì†ë„â†‘)
        device="cpu",
        verbose=False
    )

    canvas = st.empty()
    fps_hist = collections.deque(maxlen=15)
    t_prev = perf_counter()
    processed = 0

    for res in gen:
        if st.session_state[stop_key]:
            break
        processed += 1
        if processed > max_frames:
            break

        # í”„ë ˆì„ ìŠ¤í‚µ(ì¶”ë¡  ìì²´ ìƒëµ)
        if frame_skip > 1 and (processed % frame_skip) != 0:
            continue

        vis = res.plot()  # ë°•ìŠ¤/ë¼ë²¨ì„ ì˜ìƒ ì•ˆì— ì§ì ‘ ê·¸ë¦¼ (BGR)

        # í‘œì‹œ ì „ìš© ë¦¬ì‚¬ì´ì¦ˆ(ì„±ëŠ¥)
        if resize_w and vis.shape[1] > resize_w:
            h, w = vis.shape[:2]
            new_h = int(h * (resize_w / w))
            vis = cv2.resize(vis, (resize_w, new_h), interpolation=cv2.INTER_AREA)

        # FPS ê³„ì‚°(ìŠ¤ë¬´ë”©)
        t_now = perf_counter()
        dt = max(t_now - t_prev, 1e-6)
        fps_hist.append(1.0 / dt)
        t_prev = t_now
        fps_smoothed = sum(fps_hist) / len(fps_hist)

        # í´ë˜ìŠ¤ ì¹´ìš´íŠ¸ â†’ HUD
        if hud:
            counts_txt = ""
            try:
                names = _safe_names(model, res)
                cls = res.boxes.cls if (res and res.boxes is not None) else []
                cc = {}
                for c in cls:
                    c = int(c)
                    name = names[c] if isinstance(names, (list, tuple)) else names.get(c, str(c))
                    cc[name] = cc.get(name, 0) + 1
                if cc:
                    parts = [f"{k}:{v}" for k, v in sorted(cc.items(), key=lambda x: x[1], reverse=True)]
                    counts_txt = " | ".join(parts)
            except Exception:
                pass
            _put_text(vis, f"FPS: {fps_smoothed:.1f}", 28, (0, 255, 0))
            if counts_txt:
                _put_text(vis, counts_txt, 58, (255, 200, 0))

        # ì‹¤ì‹œê°„ ê°±ì‹  (ìë§‰ ì—†ì´ ì˜ìƒë§Œ)
        canvas.image(_rgb(vis), use_column_width=True)

        # ëª©í‘œ FPSë¡œ ìŠ¤ë¡œí‹€ (í‘œì‹œ ì£¼ê¸° ì œì–´)
        if target_fps > 0:
            budget = max(0.0, (1.0 / target_fps) - (perf_counter() - t_now))
            if budget > 0:
                time.sleep(budget)

    st.session_state[stop_key] = False  # ë¦¬ì…‹


# ========================= ë©”ì¸ =========================

def main():
    st.set_page_config(page_title="Wildfire Detection", page_icon="ğŸ”¥", initial_sidebar_state="collapsed")

    # ë””ë²„ê·¸ ë°°ë„ˆ: ë¹Œë“œ í™•ì¸ìš©
    st.info(f"VIDEO BUILD ACTIVE â€” {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

    # ---- Sidebar: Credits Card (optional fancy style) ----
    st.sidebar.markdown(
    """
    <style>
      .credit-card{
        padding:12px 14px; border:1px solid #e5e7eb; border-radius:12px;
        background:#fafafa; font-size:14px; line-height:1.45;
      }
      .credit-card b{font-size:15px;}
      .credit-item{ margin:6px 0; }
      .credit-card a{ text-decoration:none; }
    </style>
    <div class="credit-card">
      <div class="credit-item"><b>ğŸ‘¤ Original author</b><br/>
        <a href="https://www.linkedin.com/in/alimtleuliyev/" target="_blank">Alim Tleuliyev</a>
      </div>
      <div class="credit-item"><b>ğŸ›  Modified by</b><br/>
        <b>Wonjin Choi</b> (WOW Future Technology)
      </div>
      <hr/>
      <div class="credit-item">ğŸ™ <b>GitHub</b><br/>
        <a href="https://github.com/AlimTleuliyev/wildfire-detection" target="_blank">Original repo</a><br/>
        <a href="https://github.com/wonj6032-tech/wildfire-detection" target="_blank">This fork</a>
      </div>
    </div>
    """,
    unsafe_allow_html=True
)
  

    # íƒ€ì´í‹€/ë¡œê³ 
    st.markdown("<h1 style='text-align:center;'>Wildfire Detection</h1>", unsafe_allow_html=True)
    logos = glob('dalle-logos/*.png')
    if logos:
        logo = random.choice(logos)
        st.image(logo, use_column_width=True, caption="Generated by DALL-E")
        st.sidebar.image(logo, use_column_width=True, caption="Generated by DALL-E")

    st.markdown("---")

    # ëª¨ë¸ ì„ íƒ
    colA, colB = st.columns(2)
    with colA:
        model_type = st.radio("Select Model Type", ("Fire Detection", "General"), index=0)
    models_dir = "general-models" if model_type == "General" else "fire-models"
    model_files = sorted([f[:-3] for f in os.listdir(models_dir)]) if os.path.isdir(models_dir) else []
    with colB:
        if model_files:
            default_idx = 0
            try:
                if model_type != "General":
                    if "fire_n" in model_files: default_idx = model_files.index("fire_n")
                    elif "fire_s" in model_files: default_idx = model_files.index("fire_s")
            except Exception:
                pass
            selected_model = st.selectbox("Select Model", model_files, index=min(default_idx, len(model_files)-1))
        else:
            st.warning(f"'{models_dir}' í´ë”ì—ì„œ .pt íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            selected_model = None

    model_path = os.path.join(models_dir, f"{selected_model}.pt") if selected_model else None
    with st.spinner("Loading modelâ€¦"):
        model = load_model(model_path)

    st.markdown("---")

    # ê³µí†µ íŒŒë¼ë¯¸í„°
    colT1, colT2 = st.columns(2)
    with colT2:
        conf_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.25, 0.05)
    with colT1:
        iou_threshold = st.slider("IOU Threshold", 0.0, 1.0, 0.50, 0.05)

    st.markdown("---")

    # íƒ­ UI: Image | Video
    tab_img, tab_vid = st.tabs(["ğŸ–¼ Image", "ğŸ¥ Video"])

    with tab_img:
        image = None
        src = st.radio("Image source", ("Enter URL", "Upload from Computer"), index=0)
        if src == "Upload from Computer":
            file = st.file_uploader("Upload an image", type=["png", "jpg", "jpeg"])
            if file:
                image = Image.open(file).convert("RGB")
        else:
            url = st.text_input("Enter the image URL:", "")
            if url:
                try:
                    r = requests.get(url, timeout=20); r.raise_for_status()
                    image = Image.open(io.BytesIO(r.content)).convert("RGB")
                except Exception as e:
                    st.error(f"Error loading image: {e}")

        if image:
            with st.spinner("Detectingâ€¦"):
                pred_img, text = predict_image(model, image, conf_threshold, iou_threshold)
                st.image(pred_img, caption="Prediction", use_column_width=True)
                st.success(text)
            out = Image.fromarray(pred_img)
            buf = io.BytesIO(); out.save(buf, format="PNG")
            st.download_button("Download Prediction", data=buf.getvalue(), file_name="prediction.png", mime="image/png")

    with tab_vid:
        video_path = None
        v_src = st.radio("Video source", ("Enter URL", "Upload from Computer"), index=0)
        if v_src == "Upload from Computer":
            vfile = st.file_uploader("Upload a video", type=["mp4", "mov", "avi", "mkv"])
            if vfile:
                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                tmp.write(vfile.read()); tmp.flush()
                video_path = tmp.name
        else:
            vurl = st.text_input("Enter the video URL (mp4/mov):", "")
            if vurl:
                video_path = vurl

        c1, c2, c3 = st.columns(3)
        with c1:
            frame_skip = st.slider("Frame skip", 1, 8, 2, 1, help="í° ê°’ì¼ìˆ˜ë¡ ëœ ë§ì€ í”„ë ˆì„ ì¶”ë¡  â†’ ë” ë¹ ë¦„")
        with c2:
            resize_w = st.slider("Resize width", 320, 1280, 800, 40, help="ê°€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ(í‘œì‹œ ì„±ëŠ¥)")
        with c3:
            max_frames = st.slider("Max frames", 100, 6000, 3000, 100, help="ì•ˆì „ ì¢…ë£Œ ìƒí•œ")

        # ë¼ì´ë¸Œ ìµœì ê°’ìœ¼ë¡œ ì‹¤í–‰
        if video_path:
            if st.button("â–¶ Start video inference (Live)"):
                # í˜¹ì‹œ ì´ì „ ì •ì§€ í”Œë˜ê·¸ê°€ ë‚¨ì•„ìˆë‹¤ë©´ ì´ˆê¸°í™”
                st.session_state["stop_video"] = False
                with st.spinner("Running video inferenceâ€¦"):
                    predict_video(
                        model,
                        source=video_path,
                        conf_threshold=conf_threshold,
                        iou_threshold=iou_threshold,
                        frame_skip=frame_skip,   # 2~4 ê¶Œì¥
                        resize_w=resize_w,       # 640~960 ê¶Œì¥
                        max_frames=max_frames,
                        hud=True,
                        imgsz=480,               # 384~512 ê¶Œì¥
                        target_fps=12,           # 10~15 ê¶Œì¥
                        preview=False
                    )


if __name__ == "__main__":
    main()
