# 1_ğŸ”¥_Home.py  â€” Wildfire Detection (Image + Video)
# Streamlit Cloud (CPU) ê¸°ì¤€ ì•ˆì • ë™ì‘ìš©
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

import io
import time
import tempfile
from glob import glob

import cv2
import requests
import streamlit as st
from numpy import random
from PIL import Image
from ultralytics import YOLO


# ========================= ê³µí†µ ìœ í‹¸ =========================

def _safe_names(model, res0=None):
    """
    í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œì„ ìµœëŒ€í•œ í˜¸í™˜ì„± ìˆê²Œ ì²˜ë¦¬
    """
    # ìš°ì„  ê²°ê³¼ ê°ì²´ì— namesê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if res0 is not None and hasattr(res0, "names") and res0.names:
        return res0.names
    # ëª¨ë¸ì— namesê°€ dict/listë¡œ ìˆì„ ìˆ˜ ìˆìŒ
    if hasattr(model, "names") and model.names:
        return model.names
    if hasattr(model, "model") and hasattr(model.model, "names"):
        return model.model.names
    # ìµœí›„ì˜ ë³´ë£¨
    return {0: "object"}

def _rgb(img_bgr):
    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

def _resize_keep_aspect(frame, target_w=None, max_w=None):
    """
    frameì„ ê°€ë¡œ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ. target_wê°€ ìˆìœ¼ë©´ ê·¸ í­ìœ¼ë¡œ,
    max_wê°€ ìˆìœ¼ë©´ ê·¸ ì´í•˜ì¼ ë•Œë§Œ ì¶•ì†Œ.
    """
    h, w = frame.shape[:2]
    if target_w is not None and target_w > 0 and w != target_w:
        new_w = int(target_w)
        new_h = int(h * (new_w / w))
        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
    if max_w is not None and w > max_w:
        new_w = int(max_w)
        new_h = int(h * (new_w / w))
        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return frame


# ========================= ëª¨ë¸ ë¡œë” =========================

@st.cache_resource
def load_model(model_path: str | None):
    """
    1) ì§€ì • ê²½ë¡œì˜ .pt ë¡œë“œ ì‹œë„
    2) ì‹¤íŒ¨ ì‹œ general-models/yolov8n.pt í´ë°±
    3) ê·¸ë˜ë„ ì‹¤íŒ¨ ì‹œ ë‚´ì¥ yolov8n.pt í´ë°±
    """
    # 1) ì§ì ‘ ê²½ë¡œ ì‹œë„
    if model_path and os.path.exists(model_path) and os.path.getsize(model_path) > 1_000_00:  # >100KB
        try:
            return YOLO(model_path)
        except Exception as e:
            st.warning(f"ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}. í´ë°±ì„ ì‹œë„í•©ë‹ˆë‹¤â€¦")

    # 2) ì €ì¥ì†Œ ë‚´ ê¸°ë³¸ í´ë°±
    fallback_local = os.path.join("general-models", "yolov8n.pt")
    if os.path.exists(fallback_local):
        try:
            return YOLO(fallback_local)
        except Exception as e:
            st.warning(f"ë¡œì»¬ í´ë°± ë¡œë“œ ì‹¤íŒ¨: {e}. ìµœì¢… í´ë°±ì„ ì‹œë„í•©ë‹ˆë‹¤â€¦")

    # 3) ìµœì¢… í´ë°±: íŒ¨í‚¤ì§€ ê¸°ë³¸ ê°€ì¤‘ì¹˜
    return YOLO("yolov8n.pt")


# ========================= ì¶”ë¡  í•¨ìˆ˜ (ì´ë¯¸ì§€) =========================

def predict_image(model, image_pil: Image.Image, conf_threshold: float, iou_threshold: float):
    """
    PIL.Image ì…ë ¥ â†’ YOLO ì¶”ë¡  â†’ ì‹œê°í™”/ë¬¸êµ¬/ì§€ì—°ì‹œê°„ ë°˜í™˜
    """
    # PIL â†’ OpenCV(BGR)
    img_bgr = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)

    res = model.predict(
        img_bgr,
        conf=conf_threshold,
        iou=iou_threshold,
        device='cpu',
        verbose=False,
    )

    res0 = res[0] if res else None
    names = _safe_names(model, res0)
    classes = res0.boxes.cls if (res0 is not None and res0.boxes is not None) else []
    class_counts = {}

    if classes is not None:
        for c in classes:
            c = int(c)
            cname = names[c] if isinstance(names, (list, tuple)) else names.get(c, str(c))
            class_counts[cname] = class_counts.get(cname, 0) + 1

    if class_counts:
        parts = []
        for k, v in sorted(class_counts.items(), key=lambda item: item[1], reverse=True):
            parts.append(f"{v} {k}{'s' if v > 1 else ''}")
        prediction_text = "Predicted " + ", ".join(parts)
    else:
        prediction_text = "No objects detected"

    latency_ms = sum(res0.speed.values()) if (res0 is not None and hasattr(res0, "speed")) else 0.0
    prediction_text += f" in {round(latency_ms / 1000, 2)} seconds."

    vis = res0.plot() if res0 is not None else img_bgr
    return _rgb(vis), prediction_text


# ========================= ì¶”ë¡  í•¨ìˆ˜ (ë¹„ë””ì˜¤) =========================

def predict_video(model,
                  source,
                  conf_threshold: float,
                  iou_threshold: float,
                  frame_skip: int = 2,
                  resize_w: int | None = 960,
                  max_frames: int = 1200,
                  stop_flag_key: str = "stop_video"):
    """
    source: íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URL
    frame_skip: nì´ë©´ 1/n í”„ë ˆì„ë§Œ ì²˜ë¦¬
    resize_w: ê°€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í­(ë„ˆë¬´ í° ì˜ìƒ ì„±ëŠ¥ ë³´ì •)
    max_frames: ì•ˆì „ ì¢…ë£Œìš© ìµœëŒ€ ì²˜ë¦¬ í”„ë ˆì„
    stop_flag_key: ì„¸ì…˜ í‚¤ë¡œ Stop ë²„íŠ¼ ì—°ë™
    """
    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        st.error("Failed to open video.")
        return

    canvas = st.empty()
    info = st.empty()

    processed = 0
    t0 = time.time()

    # Stop ë²„íŠ¼
    if stop_flag_key not in st.session_state:
        st.session_state[stop_flag_key] = False

    stop_col1, stop_col2, stop_col3 = st.columns([1, 1, 2])
    with stop_col1:
        if st.button("â¹ Stop"):
            st.session_state[stop_flag_key] = True
    with stop_col2:
        st.caption("Stopì„ ëˆ„ë¥´ë©´ ë‹¤ìŒ ë£¨í”„ì—ì„œ ì¢…ë£Œë©ë‹ˆë‹¤.")

    while True:
        if st.session_state[stop_flag_key]:
            info.info("Stopped by user.")
            break

        ret, frame = cap.read()
        if not ret:
            break
        processed += 1

        # í”„ë ˆì„ ìŠ¤í‚µ
        if frame_skip > 1 and (processed % frame_skip) != 0:
            continue

        # ë¦¬ì‚¬ì´ì¦ˆ
        frame = _resize_keep_aspect(frame, target_w=resize_w if resize_w and resize_w > 0 else None)

        # ì¶”ë¡ 
        res = model.predict(
            frame,
            conf=conf_threshold,
            iou=iou_threshold,
            device="cpu",
            verbose=False,
        )
        res0 = res[0] if res else None
        vis = res0.plot() if res0 is not None else frame

        canvas.image(_rgb(vis), caption=f"Frame {processed}", use_column_width=True)

        # ì§„í–‰ ì •ë³´
        elapsed = time.time() - t0
        fps = (processed / elapsed) if elapsed > 0 else 0.0
        info.info(f"Processed: {processed} frames  |  ~{fps:.1f} FPS (incl. skip, resized)")
        if processed >= max_frames:
            st.warning("Max frames reached; stopping.")
            break

    cap.release()
    st.session_state[stop_flag_key] = False  # ë‹¤ìŒ ì‹¤í–‰ì„ ìœ„í•´ ë¦¬ì…‹


# ========================= ë©”ì¸ ì•± =========================

import numpy as np  # (ì—¬ê¸° ë‘ëŠ” ì´ìœ : predict_imageì—ì„œ np ì‚¬ìš©)

def main():
    st.set_page_config(page_title="Wildfire Detection", page_icon="ğŸ”¥", initial_sidebar_state="collapsed")

    # ì‚¬ì´ë“œë°” ì •ë³´
    st.sidebar.markdown("Developed by Alim Tleuliyev")
    st.sidebar.markdown("LinkedIn: [Profile](https://www.linkedin.com/in/alimtleuliyev/)")
    st.sidebar.markdown("GitHub: [Repo](https://github.com/AlimTleuliyev/wildfire-detection)")
    st.sidebar.markdown("Email: [alim.tleuliyev@nu.edu.kz](mailto:alim.tleuliyev@nu.edu.kz)")
    st.sidebar.markdown("Telegram: [@nativealim](https://t.me/nativealim)")

    # ê°„ë‹¨ ìŠ¤íƒ€ì¼
    st.markdown(
        """
        <style>
        .container { max-width: 900px; }
        .title { text-align: center; font-size: 35px; font-weight: bold; margin-bottom: 10px; }
        </style>
        """,
        unsafe_allow_html=True
    )
    st.markdown("<div class='title'>Wildfire Detection</div>", unsafe_allow_html=True)

    # ë¡œê³ 
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        logos = glob('dalle-logos/*.png')
        if logos:
            logo = random.choice(logos)
            st.image(logo, use_column_width=True, caption="Generated by DALL-E")
            st.sidebar.image(logo, use_column_width=True, caption="Generated by DALL-E")

    # ì„¤ëª…
    st.markdown(
        """
        <div style='text-align: center;'>
            <h2>ğŸ”¥ <strong>Wildfire Detection App</strong></h2>
            <p>Powered by <a href='https://github.com/ultralytics/ultralytics'>YOLOv8</a> trained on <a href='https://github.com/gaiasd/DFireDataset'>D-Fire</a>.</p>
            <p>Upload an image/video or provide a URL to test.</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    st.markdown("---")

    # ëª¨ë¸ ì„ íƒ
    colA, colB = st.columns(2)
    with colA:
        model_type = st.radio("Select Model Type", ("Fire Detection", "General"), index=0)

    models_dir = "general-models" if model_type == "General" else "fire-models"
    model_files = []
    if os.path.isdir(models_dir):
        model_files = sorted([f[:-3] for f in os.listdir(models_dir) if f.endswith(".pt")])

    with colB:
        if model_files:
            # fire_n/fire_s ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë¶€í„° ì„ íƒë˜ê²Œ
            default_idx = 0
            try:
                if model_type != "General":
                    if "fire_n" in model_files:
                        default_idx = model_files.index("fire_n")
                    elif "fire_s" in model_files:
                        default_idx = model_files.index("fire_s")
            except Exception:
                pass
            selected_model = st.selectbox("Select Model", model_files, index=min(default_idx, len(model_files)-1))
        else:
            st.warning(f"'{models_dir}' í´ë”ì—ì„œ .pt íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            selected_model = None

    model_path = os.path.join(models_dir, f"{selected_model}.pt") if selected_model else None
    with st.spinner("Loading modelâ€¦"):
        model = load_model(model_path)

    st.markdown("---")

    # ëª¨ë“œ: ì´ë¯¸ì§€ / ë¹„ë””ì˜¤
    media_kind = st.radio("What to test?", ("Image", "Video"), index=0)

    # ê³µí†µ íŒŒë¼ë¯¸í„°
    colT1, colT2 = st.columns(2)
    with colT2:
        conf_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.20, 0.05)
    with colT1:
        iou_threshold = st.slider("IOU Threshold", 0.0, 1.0, 0.50, 0.05)

    st.markdown("---")

    if media_kind == "Image":
        # ===== ì´ë¯¸ì§€ ì…ë ¥ =====
        image = None
        src = st.radio("Image source", ("Enter URL", "Upload from Computer"), index=0)

        if src == "Upload from Computer":
            file = st.file_uploader("Upload an image", type=["png", "jpg", "jpeg"])
            if file:
                image = Image.open(file).convert("RGB")
        else:
            url = st.text_input("Enter the image URL:", "")
            if url:
                try:
                    r = requests.get(url, timeout=20)
                    r.raise_for_status()
                    image = Image.open(io.BytesIO(r.content)).convert("RGB")
                except Exception as e:
                    st.error(f"Error loading image: {e}")

        if image:
            with st.spinner("Detectingâ€¦"):
                pred_img, text = predict_image(model, image, conf_threshold, iou_threshold)
                st.image(pred_img, caption="Prediction", use_column_width=True)
                st.success(text)

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            out = Image.fromarray(pred_img)
            buf = io.BytesIO()
            out.save(buf, format="PNG")
            st.download_button("Download Prediction", data=buf.getvalue(), file_name="prediction.png", mime="image/png")

    else:
        # ===== ë¹„ë””ì˜¤ ì…ë ¥ =====
        video_path = None
        v_src = st.radio("Video source", ("Enter URL", "Upload from Computer"), index=0)

        if v_src == "Upload from Computer":
            vfile = st.file_uploader("Upload a video", type=["mp4", "mov", "avi", "mkv"])
            if vfile:
                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                tmp.write(vfile.read())
                tmp.flush()
                video_path = tmp.name
        else:
            vurl = st.text_input("Enter the video URL (mp4/mov):", "")
            if vurl:
                video_path = vurl

        # ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        c1, c2, c3 = st.columns(3)
        with c1:
            frame_skip = st.slider("Frame skip", 1, 8, 2, 1, help="í° ê°’ì¼ìˆ˜ë¡ ëœ ë§ì€ í”„ë ˆì„ì„ ì²˜ë¦¬ â†’ ë” ë¹ ë¦„")
        with c2:
            resize_w = st.slider("Resize width", 320, 1280, 960, 40, help="ê°€ë¡œ í­ ë¦¬ì‚¬ì´ì¦ˆ(ì„±ëŠ¥ í–¥ìƒìš©)")
        with c3:
            max_frames = st.slider("Max frames", 100, 4000, 1200, 100, help="ì•ˆì „ ì¢…ë£Œìš© ìµœëŒ€ ì²˜ë¦¬ í”„ë ˆì„")

        if video_path:
            if st.button("â–¶ Start video inference"):
                with st.spinner("Running video inferenceâ€¦"):
                    predict_video(model,
                                  source=video_path,
                                  conf_threshold=conf_threshold,
                                  iou_threshold=iou_threshold,
                                  frame_skip=frame_skip,
                                  resize_w=resize_w,
                                  max_frames=max_frames)

    # í•˜ë‹¨ ì•ˆë‚´
    st.markdown("---")
    st.caption("Tip: CloudëŠ” CPU í™˜ê²½ì…ë‹ˆë‹¤. í”„ë ˆì„ ìŠ¤í‚µ/ë¦¬ì‚¬ì´ì¦ˆë¥¼ ì¡°ì ˆí•˜ë©´ ë” ë§¤ë„ëŸ½ê²Œ ë™ì‘í•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
