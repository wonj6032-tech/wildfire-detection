# 1_ğŸ”¥_Home.py â€” Wildfire Detection (Image + Video)
# Streamlit Cloud (CPU) í™˜ê²½ í˜¸í™˜ / ì´ë¯¸ì§€ & ë¹„ë””ì˜¤ í†µí•©
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

import io
import time
import tempfile
from glob import glob

import cv2
import requests
import streamlit as st
import numpy as np
from numpy import random
from PIL import Image
from ultralytics import YOLO


# ========================= ê³µí†µ ìœ í‹¸ =========================

def _rgb(img_bgr):
    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

def _resize_keep_aspect(frame, target_w=None, max_w=None):
    """ê°€ë¡œ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ(ì„±ëŠ¥ ë³´ì •ìš©)."""
    h, w = frame.shape[:2]
    if target_w is not None and target_w > 0 and w != target_w:
        new_w = int(target_w)
        new_h = int(h * (new_w / w))
        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
    if max_w is not None and w > max_w:
        new_w = int(max_w)
        new_h = int(h * (new_w / w))
        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return frame

def _safe_names(model, res0=None):
    """í´ë˜ìŠ¤ ì´ë¦„ ì•ˆì „ ì¶”ì¶œ."""
    if res0 is not None and hasattr(res0, "names") and res0.names:
        return res0.names
    if hasattr(model, "names") and model.names:
        return model.names
    if hasattr(model, "model") and hasattr(model.model, "names"):
        return model.model.names
    return {0: "object"}

def _looks_like_lfs_pointer(path: str) -> bool:
    """LFS í¬ì¸í„° íŒŒì¼ ê°„ë‹¨ ê°ì§€(ì•ˆì „ìš©)."""
    try:
        with open(path, "rb") as f:
            head = f.read(256)
        return b"git-lfs" in head or b"oid sha256" in head or b"version https://git-lfs.github.com/spec" in head
    except Exception:
        return False


# ========================= ëª¨ë¸ ë¡œë” =========================

@st.cache_resource
def load_model(model_path: str | None):
    """
    1) ì§€ì • ê²½ë¡œ .pt ë¡œë“œ
    2) ì‹¤íŒ¨ ì‹œ ì €ì¥ì†Œì˜ general-models/yolov8n.pt í´ë°±
    3) ìµœì¢… í´ë°±: íŒ¨í‚¤ì§€ yolov8n.pt
    """
    # 1) ì‚¬ìš©ì ì„ íƒ ê²½ë¡œ
    if model_path and os.path.exists(model_path) and os.path.getsize(model_path) > 100_000 and not _looks_like_lfs_pointer(model_path):
        try:
            return YOLO(model_path)
        except Exception as e:
            st.warning(f"ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨({e}). í´ë°± ì‹œë„â€¦")

    # 2) ì €ì¥ì†Œ í´ë°±
    fallback_local = os.path.join("general-models", "yolov8n.pt")
    if os.path.exists(fallback_local) and not _looks_like_lfs_pointer(fallback_local):
        try:
            return YOLO(fallback_local)
        except Exception as e:
            st.warning(f"ë¡œì»¬ í´ë°± ë¡œë“œ ì‹¤íŒ¨({e}). ìµœì¢… í´ë°± ì‹œë„â€¦")

    # 3) ìµœì¢… í´ë°±
    return YOLO("yolov8n.pt")


# ========================= ì¶”ë¡  (ì´ë¯¸ì§€) =========================

def predict_image(model, image_pil: Image.Image, conf_threshold: float, iou_threshold: float):
    """PIL.Image -> YOLO ì¶”ë¡  -> ì‹œê°í™”/ë¬¸êµ¬/ì§€ì—°ì‹œê°„ ë°˜í™˜."""
    img_bgr = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)

    res = model.predict(
        img_bgr,
        conf=conf_threshold,
        iou=iou_threshold,
        device='cpu',
        verbose=False,
    )

    res0 = res[0] if res else None
    names = _safe_names(model, res0)
    classes = res0.boxes.cls if (res0 is not None and res0.boxes is not None) else []
    class_counts = {}

    if classes is not None:
        for c in classes:
            c = int(c)
            cname = names[c] if isinstance(names, (list, tuple)) else names.get(c, str(c))
            class_counts[cname] = class_counts.get(cname, 0) + 1

    if class_counts:
        parts = []
        for k, v in sorted(class_counts.items(), key=lambda item: item[1], reverse=True):
            parts.append(f"{v} {k}{'s' if v > 1 else ''}")
        prediction_text = "Predicted " + ", ".join(parts)
    else:
        prediction_text = "No objects detected"

    latency_ms = sum(res0.speed.values()) if (res0 is not None and hasattr(res0, "speed")) else 0.0
    prediction_text += f" in {round(latency_ms / 1000, 2)} seconds."

    vis = res0.plot() if res0 is not None else img_bgr
    return _rgb(vis), prediction_text


# ========================= ì¶”ë¡  (ë¹„ë””ì˜¤) =========================

def _resolve_video_source(src: str) -> str:
    """
    ì›ê²© URLì´ë©´ ì„ì‹œíŒŒì¼ë¡œ ì €ì¥í•´ì„œ OpenCVê°€ ì•ˆì •ì ìœ¼ë¡œ ì—´ë„ë¡ ë³€í™˜.
    ë¡œì»¬ ê²½ë¡œ/ì—…ë¡œë“œ íŒŒì¼ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜.
    """
    if isinstance(src, str) and src.startswith(("http://", "https://")):
        suffix = os.path.splitext(src)[1] or ".mp4"
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        with requests.get(src, stream=True, timeout=60) as r:
            r.raise_for_status()
            for chunk in r.iter_content(1 << 20):
                if chunk:
                    tmp.write(chunk)
        tmp.flush()
        return tmp.name
    return src

def predict_video(model,
                  source,
                  conf_threshold: float,
                  iou_threshold: float,
                  frame_skip: int = 2,
                  resize_w: int | None = 960,
                  max_frames: int = 1200,
                  stop_flag_key: str = "stop_video"):
    """
    source: íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URL(ë‚´ë¶€ì—ì„œ ì„ì‹œíŒŒì¼ ë³€í™˜)
    frame_skip: nì´ë©´ 1/n í”„ë ˆì„ë§Œ ì¶”ë¡ 
    resize_w: ê°€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ(ì„±ëŠ¥ ë³´ì •)
    max_frames: ì•ˆì „ ì¢…ë£Œ ìƒí•œ
    """
    path = _resolve_video_source(source)
    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        st.error("Failed to open video.")
        return

    canvas = st.empty()
    info = st.empty()
    processed = 0
    t0 = time.time()

    if stop_flag_key not in st.session_state:
        st.session_state[stop_flag_key] = False

    stop_col1, stop_col2, _ = st.columns([1, 2, 2])
    with stop_col1:
        if st.button("â¹ Stop"):
            st.session_state[stop_flag_key] = True
    with stop_col2:
        st.caption("Stopì„ ëˆ„ë¥´ë©´ ë‹¤ìŒ ë£¨í”„ì—ì„œ ì¢…ë£Œë©ë‹ˆë‹¤.")

    while True:
        if st.session_state[stop_flag_key]:
            info.info("Stopped by user.")
            break

        ret, frame = cap.read()
        if not ret:
            break
        processed += 1

        # í”„ë ˆì„ ìŠ¤í‚µ
        if frame_skip > 1 and (processed % frame_skip) != 0:
            continue

        # ë¦¬ì‚¬ì´ì¦ˆ
        if resize_w and frame.shape[1] > resize_w:
            h, w = frame.shape[:2]
            new_h = int(h * (resize_w / w))
            frame = cv2.resize(frame, (resize_w, new_h), interpolation=cv2.INTER_AREA)

        # ì¶”ë¡ 
        res = model.predict(
            frame,
            conf=conf_threshold,
            iou=iou_threshold,
            device="cpu",
            verbose=False,
        )
        vis = res[0].plot() if res else frame
        canvas.image(_rgb(vis), caption=f"Frame {processed}", use_column_width=True)

        elapsed = time.time() - t0
        fps = (processed / elapsed) if elapsed > 0 else 0.0
        info.info(f"Processed: {processed} frames  |  ~{fps:.1f} FPS (incl. skip, resized)")

        if processed >= max_frames:
            st.warning("Max frames reached; stopping.")
            break

    cap.release()
    st.session_state[stop_flag_key] = False  # ë¦¬ì…‹


# ========================= ë©”ì¸ ì•± =========================

def main():
    st.set_page_config(page_title="Wildfire Detection", page_icon="ğŸ”¥", initial_sidebar_state="collapsed")

    # ì‚¬ì´ë“œë°” ì •ë³´
    st.sidebar.markdown("Developed by Alim Tleuliyev")
    st.sidebar.markdown("LinkedIn: [Profile](https://www.linkedin.com/in/alimtleuliyev/)")
    st.sidebar.markdown("GitHub: [Repo](https://github.com/AlimTleuliyev/wildfire-detection)")
    st.sidebar.markdown("Email: [alim.tleuliyev@nu.edu.kz](mailto:alim.tleuliyev@nu.edu.kz)")
    st.sidebar.markdown("Telegram: [@nativealim](https://t.me/nativealim)")

    # ê°„ë‹¨ ìŠ¤íƒ€ì¼ & íƒ€ì´í‹€
    st.markdown(
        """
        <style>
        .container { max-width: 900px; }
        .title { text-align: center; font-size: 35px; font-weight: bold; margin-bottom: 10px; }
        </style>
        """,
        unsafe_allow_html=True
    )
    st.markdown("<div class='title'>Wildfire Detection</div>", unsafe_allow_html=True)

    # ë¡œê³ 
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        logos = glob('dalle-logos/*.png')
        if logos:
            logo = random.choice(logos)
            st.image(logo, use_column_width=True, caption="Generated by DALL-E")
            st.sidebar.image(logo, use_column_width=True, caption="Generated by DALL-E")

    # ì„¤ëª…
    st.markdown(
        """
        <div style='text-align: center;'>
            <h2>ğŸ”¥ <strong>Wildfire Detection App</strong></h2>
            <p>Powered by <a href='https://github.com/ultralytics/ultralytics'>YOLOv8</a> (D-Fire ë°ì´í„° ê¸°ë°˜).</p>
            <p>ì´ë¯¸ì§€/ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ URLì„ ì…ë ¥í•´ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    st.markdown("---")

    # ëª¨ë¸ ì„ íƒ
    colA, colB = st.columns(2)
    with colA:
        model_type = st.radio("Select Model Type", ("Fire Detection", "General"), index=0)

    models_dir = "general-models" if model_type == "General" else "fire-models"
    model_files = []
    if os.path.isdir(models_dir):
        model_files = sorted([f[:-3] for f in os.listdir(models_dir) if f.endswith(".pt")])

    with colB:
        if model_files:
            default_idx = 0
            try:
                if model_type != "General":
                    if "fire_n" in model_files:
                        default_idx = model_files.index("fire_n")
                    elif "fire_s" in model_files:
                        default_idx = model_files.index("fire_s")
            except Exception:
                pass
            selected_model = st.selectbox("Select Model", model_files, index=min(default_idx, len(model_files)-1))
        else:
            st.warning(f"'{models_dir}' í´ë”ì—ì„œ .pt íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            selected_model = None

    model_path = os.path.join(models_dir, f"{selected_model}.pt") if selected_model else None
    with st.spinner("Loading modelâ€¦"):
        model = load_model(model_path)

    st.markdown("---")

    # ê³µí†µ íŒŒë¼ë¯¸í„°
    media_kind = st.radio("What to test?", ("Image", "Video"), index=0)

    colT1, colT2 = st.columns(2)
    with colT2:
        conf_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.20, 0.05)
    with colT1:
        iou_threshold = st.slider("IOU Threshold", 0.0, 1.0, 0.50, 0.05)

    st.markdown("---")

    if media_kind == "Image":
        # ===== ì´ë¯¸ì§€ ì…ë ¥ =====
        image = None
        src = st.radio("Image source", ("Enter URL", "Upload from Computer"), index=0)

        if src == "Upload from Computer":
            file = st.file_uploader("Upload an image", type=["png", "jpg", "jpeg"])
            if file:
                image = Image.open(file).convert("RGB")
        else:
            url = st.text_input("Enter the image URL:", "")
            if url:
                try:
                    r = requests.get(url, timeout=20)
                    r.raise_for_status()
                    image = Image.open(io.BytesIO(r.content)).convert("RGB")
                except Exception as e:
                    st.error(f"Error loading image: {e}")

        if image:
            with st.spinner("Detectingâ€¦"):
                pred_img, text = predict_image(model, image, conf_threshold, iou_threshold)
                st.image(pred_img, caption="Prediction", use_column_width=True)
                st.success(text)

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            out = Image.fromarray(pred_img)
            buf = io.BytesIO()
            out.save(buf, format="PNG")
            st.download_button("Download Prediction", data=buf.getvalue(), file_name="prediction.png", mime="image/png")

    else:
        # ===== ë¹„ë””ì˜¤ ì…ë ¥ =====
        video_path = None
        v_src = st.radio("Video source", ("Enter URL", "Upload from Computer"), index=0)

        if v_src == "Upload from Computer":
            vfile = st.file_uploader("Upload a video", type=["mp4", "mov", "avi", "mkv"])
            if vfile:
                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                tmp.write(vfile.read())
                tmp.flush()
                video_path = tmp.name
        else:
            vurl = st.text_input("Enter the video URL (mp4/mov):", "")
            if vurl:
                video_path = vurl

        # ì„±ëŠ¥ ì¡°ì ˆ
        c1, c2, c3 = st.columns(3)
        with c1:
            frame_skip = st.slider("Frame skip", 1, 8, 2, 1, help="í° ê°’ì¼ìˆ˜ë¡ ëœ ë§ì€ í”„ë ˆì„ ì¶”ë¡  â†’ ë” ë¹ ë¦„")
        with c2:
            resize_w = st.slider("Resize width", 320, 1280, 960, 40, help="ê°€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ(ì„±ëŠ¥ í–¥ìƒ)")
        with c3:
            max_frames = st.slider("Max frames", 100, 4000, 1200, 100, help="ì•ˆì „ ì¢…ë£Œ ìƒí•œ")

        if video_path:
            if st.button("â–¶ Start video inference"):
                with st.spinner("Running video inferenceâ€¦"):
                    predict_video(model,
                                  source=video_path,
                                  conf_threshold=conf_threshold,
                                  iou_threshold=iou_threshold,
                                  frame_skip=frame_skip,
                                  resize_w=resize_w,
                                  max_frames=max_frames)

    # í•˜ë‹¨ ì•ˆë‚´
    st.markdown("---")
    st.caption("Tip: CloudëŠ” CPU í™˜ê²½ì…ë‹ˆë‹¤. Frame skip/Resizeë¥¼ ì¡°ì ˆí•˜ë©´ ë” ë§¤ë„ëŸ½ê²Œ ë™ì‘í•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
